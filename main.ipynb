{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source:\n",
    "https://www.kaggle.com/datasets/andrewmvd/animal-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import torchmetrics\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root='data/afhq/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "# Dataset of only dogs\n",
    "dataset = torch.utils.data.Subset(dataset, indices=[i for i in range(len(dataset)) if dataset.targets[i] == 1])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    nn.Unflatten(1, (100, 1, 1)),\n",
    "    nn.BatchNorm2d(100),\n",
    "    nn.ConvTranspose2d(100, 1024, 4, 1, 0),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(1024),\n",
    "    nn.ConvTranspose2d(1024, 512, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ConvTranspose2d(128, 3, 4, 2, 1),\n",
    "    nn.Tanh()\n",
    "    \n",
    ")\n",
    "\n",
    "discriminator = nn.Sequential(\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.Conv2d(3, 128, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Conv2d(128, 256, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.Conv2d(256, 512, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.Conv2d(512, 1024, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(1024),\n",
    "    nn.Conv2d(1024, 1, 4, 1, 0),\n",
    "    nn.Sigmoid()\n",
    "    \n",
    ")\n",
    "\n",
    "class GAN(L.LightningModule):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.automatic_optimization = False\n",
    "        self.metric = torchmetrics.image.fid.FrechetInceptionDistance(feature=64, normalize=True)\n",
    "\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g_opt, d_opt = self.optimizers()\n",
    "        real_imgs, real_labels = batch\n",
    "        \n",
    "        # Train discriminator\n",
    "        for idx in range(1):\n",
    "            d_opt.zero_grad()\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            real_preds = self.discriminator(real_imgs)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            real_loss = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            fake_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            d_opt.step()\n",
    "        \n",
    "        # Train generator\n",
    "        for idx in range(2):\n",
    "            g_opt.zero_grad()\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            g_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.ones_like(fake_preds))\n",
    "            g_loss.backward()\n",
    "            g_opt.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            real_preds = self.discriminator(real_imgs)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            real_loss = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            fake_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            d_loss = real_loss + fake_loss\n",
    "            g_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.ones_like(fake_preds))\n",
    "            \n",
    "            \n",
    "            # Calculate FID\n",
    "            fake_imgs = F.interpolate(fake_imgs, size=(299, 299), mode='nearest').detach()\n",
    "            real_imgs = F.interpolate(real_imgs, size=(299, 299), mode='nearest').detach()\n",
    "\n",
    "            self.metric.update(fake_imgs, real=False)\n",
    "            self.metric.update(real_imgs, real=True)\n",
    "            \n",
    "            fid_score = self.metric.compute()\n",
    "            \n",
    "            self.metric.reset()\n",
    "            self.logger.experiment.log({\n",
    "                \"Generator Loss\": g_loss.item(),\n",
    "                \"Discriminator Loss\": d_loss.item(),\n",
    "                \"Discriminator Accuracy\": (real_preds > 0.5).float().mean().item(),\n",
    "                \"Discriminator Loss Real\": real_loss.item(),\n",
    "                \"Discriminator Loss Fake\": fake_loss.item(),\n",
    "                \"Generated Images\": wandb.Image(torchvision.utils.make_grid(fake_imgs, nrow=32), caption=f\"Generated Images Epoch {self.current_epoch}, Batch {batch_idx}\"),\n",
    "                \"FID Score\": fid_score\n",
    "                })\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        g_opt = optim.Adam(self.generator.parameters(), lr=0.0002)\n",
    "        d_opt = optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "        return [g_opt, d_opt], []\n",
    "\n",
    "gan = GAN(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaranravindra\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a497542e013941aea3d150e00584e63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112505477778237, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240228_182911-r3zq6q33</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karanravindra/gan/runs/r3zq6q33' target=\"_blank\">glorious-dragon-59</a></strong> to <a href='https://wandb.ai/karanravindra/gan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karanravindra/gan' target=\"_blank\">https://wandb.ai/karanravindra/gan</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karanravindra/gan/runs/r3zq6q33' target=\"_blank\">https://wandb.ai/karanravindra/gan/runs/r3zq6q33</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | generator     | Sequential               | 12.7 M\n",
      "1 | discriminator | Sequential               | 11.0 M\n",
      "2 | metric        | FrechetInceptionDistance | 23.9 M\n",
      "-----------------------------------------------------------\n",
      "23.7 M    Trainable params\n",
      "23.9 M    Non-trainable params\n",
      "47.5 M    Total params\n",
      "190.199   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e66fc28e3514a3cb98192cfbd2c34cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"gan\", tags=[\"conv\", \"dcgan\"])\n",
    "trainer = Trainer(max_epochs=10, logger=logger, limit_val_batches=1)\n",
    "trainer.fit(gan, dataloader)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901d0ae279ad45379411bd6f720d0b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-star-47</strong> at: <a href='https://wandb.ai/karanravindra/gan/runs/kd46r2kw' target=\"_blank\">https://wandb.ai/karanravindra/gan/runs/kd46r2kw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240228_173457-kd46r2kw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
