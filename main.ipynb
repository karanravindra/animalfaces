{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source:\n",
    "https://www.kaggle.com/datasets/andrewmvd/animal-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import torchmetrics\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root='data/afhq/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "# Dataset of only dogs\n",
    "dataset = torch.utils.data.Subset(dataset, indices=[i for i in range(len(dataset)) if dataset.targets[i] == 1])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    nn.Unflatten(1, (100, 1, 1)),\n",
    "    nn.BatchNorm2d(100),\n",
    "    nn.ConvTranspose2d(100, 256, 4, 1, 0),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
    "    nn.Tanh()\n",
    "    \n",
    ")\n",
    "\n",
    "discriminator = nn.Sequential(\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.Conv2d(3, 32, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Conv2d(32, 64, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 128, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Conv2d(128, 256, 4, 2, 1),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256*4*4, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "class GAN(L.LightningModule):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.automatic_optimization = False\n",
    "        self.metric = torchmetrics.image.fid.FrechetInceptionDistance(feature=64, normalize=True)\n",
    "\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g_opt, d_opt = self.optimizers()\n",
    "        real_imgs, real_labels = batch\n",
    "        \n",
    "        # Train discriminator\n",
    "        for idx in range(1):\n",
    "            d_opt.zero_grad()\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            real_preds = self.discriminator(real_imgs)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            real_loss = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            fake_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            d_opt.step()\n",
    "        \n",
    "        # Train generator\n",
    "        for idx in range(2):\n",
    "            g_opt.zero_grad()\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            g_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.ones_like(fake_preds))\n",
    "            g_loss.backward()\n",
    "            g_opt.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            z = torch.randn(real_imgs.shape[0], 100, device=self.device)\n",
    "            fake_imgs = self.generator(z)\n",
    "            real_preds = self.discriminator(real_imgs)\n",
    "            fake_preds = self.discriminator(fake_imgs)\n",
    "            real_loss = F.binary_cross_entropy_with_logits(real_preds, torch.ones_like(real_preds))\n",
    "            fake_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.zeros_like(fake_preds))\n",
    "            d_loss = real_loss + fake_loss\n",
    "            g_loss = F.binary_cross_entropy_with_logits(fake_preds, torch.ones_like(fake_preds))\n",
    "            \n",
    "            \n",
    "            # Calculate FID\n",
    "            fake_imgs = F.interpolate(fake_imgs, size=(299, 299), mode='nearest').detach()\n",
    "            real_imgs = F.interpolate(real_imgs, size=(299, 299), mode='nearest').detach()\n",
    "\n",
    "            self.metric.update(fake_imgs, real=False)\n",
    "            self.metric.update(real_imgs, real=True)\n",
    "            \n",
    "            fid_score = self.metric.compute()\n",
    "            \n",
    "            self.metric.reset()\n",
    "            self.logger.experiment.log({\n",
    "                \"Generator Loss\": g_loss.item(),\n",
    "                \"Discriminator Loss\": d_loss.item(),\n",
    "                \"Discriminator Accuracy\": (real_preds > 0.5).float().mean().item(),\n",
    "                \"Discriminator Loss Real\": real_loss.item(),\n",
    "                \"Discriminator Loss Fake\": fake_loss.item(),\n",
    "                \"Generated Images\": wandb.Image(torchvision.utils.make_grid(fake_imgs, nrow=32), caption=f\"Generated Images Epoch {self.current_epoch}, Batch {batch_idx}\"),\n",
    "                \"FID Score\": fid_score\n",
    "                })\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        g_opt = optim.Adam(self.generator.parameters(), lr=0.0002)\n",
    "        d_opt = optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "        return [g_opt, d_opt], []\n",
    "\n",
    "gan = GAN(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240228_183756-esgpxpmb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karanravindra/gan/runs/esgpxpmb' target=\"_blank\">smooth-plant-62</a></strong> to <a href='https://wandb.ai/karanravindra/gan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karanravindra/gan' target=\"_blank\">https://wandb.ai/karanravindra/gan</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karanravindra/gan/runs/esgpxpmb' target=\"_blank\">https://wandb.ai/karanravindra/gan/runs/esgpxpmb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | generator     | Sequential               | 1.1 M \n",
      "1 | discriminator | Sequential               | 694 K \n",
      "2 | metric        | FrechetInceptionDistance | 23.9 M\n",
      "-----------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "23.9 M    Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.586   Total estimated model params size (MB)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa31874f4084469bcd3cb5f033f8750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  3259           \t|  107.34         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  10.343         \t|  10             \t|  103.43         \t|  96.354         \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  1.0117         \t|  100            \t|  101.17         \t|  94.245         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  1.0116         \t|  100            \t|  101.16         \t|  94.237         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.32537        \t|  10             \t|  3.2537         \t|  3.0311         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.018216       \t|  100            \t|  1.8216         \t|  1.697          \t|\n",
      "|  optimizer_step                                                                                                                                                \t|  0.0047657      \t|  300            \t|  1.4297         \t|  1.3319         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.002161       \t|  100            \t|  0.2161         \t|  0.20132        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.0020588      \t|  10             \t|  0.020588       \t|  0.01918        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.020223       \t|  1              \t|  0.020223       \t|  0.01884        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  0.00010917     \t|  100            \t|  0.010917       \t|  0.01017        \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.0086135      \t|  1              \t|  0.0086135      \t|  0.0080244      \t|\n",
      "|  [LightningModule]GAN.transfer_batch_to_device                                                                                                                 \t|  6.1187e-05     \t|  100            \t|  0.0061187      \t|  0.0057001      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  2.9973e-05     \t|  100            \t|  0.0029973      \t|  0.0027923      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.000214       \t|  10             \t|  0.00214        \t|  0.0019936      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  6.5214e-06     \t|  300            \t|  0.0019564      \t|  0.0018226      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.00083899     \t|  1              \t|  0.00083899     \t|  0.0007816      \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  2.497e-06      \t|  300            \t|  0.00074911     \t|  0.00069787     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  6.8019e-06     \t|  100            \t|  0.00068019     \t|  0.00063366     \t|\n",
      "|  [LightningModule]GAN.on_before_optimizer_step                                                                                                                 \t|  2.1252e-06     \t|  300            \t|  0.00063755     \t|  0.00059394     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  1.9982e-06     \t|  300            \t|  0.00059947     \t|  0.00055846     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  0.00044462     \t|  1              \t|  0.00044462     \t|  0.00041421     \t|\n",
      "|  [LightningModule]GAN.configure_optimizers                                                                                                                     \t|  0.0003951      \t|  1              \t|  0.0003951      \t|  0.00036808     \t|\n",
      "|  [LightningModule]GAN.on_before_batch_transfer                                                                                                                 \t|  3.1041e-06     \t|  100            \t|  0.00031041     \t|  0.00028917     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  2.882e-06      \t|  100            \t|  0.0002882      \t|  0.00026849     \t|\n",
      "|  [LightningModule]GAN.on_train_batch_end                                                                                                                       \t|  2.3423e-06     \t|  100            \t|  0.00023423     \t|  0.00021821     \t|\n",
      "|  [LightningModule]GAN.on_train_batch_start                                                                                                                     \t|  2.2611e-06     \t|  100            \t|  0.00022611     \t|  0.00021064     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  1.9734e-06     \t|  100            \t|  0.00019734     \t|  0.00018384     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  1.9101e-06     \t|  100            \t|  0.00019101     \t|  0.00017795     \t|\n",
      "|  [LightningModule]GAN.on_after_batch_transfer                                                                                                                  \t|  1.609e-06      \t|  100            \t|  0.0001609      \t|  0.00014989     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  1.5951e-06     \t|  100            \t|  0.00015951     \t|  0.0001486      \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  5.2083e-06     \t|  10             \t|  5.2083e-05     \t|  4.852e-05      \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  4.3893e-06     \t|  10             \t|  4.3893e-05     \t|  4.0891e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  3.649e-06      \t|  10             \t|  3.649e-05      \t|  3.3994e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  2.6662e-06     \t|  10             \t|  2.6662e-05     \t|  2.4838e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  2.1677e-06     \t|  10             \t|  2.1677e-05     \t|  2.0194e-05     \t|\n",
      "|  [LightningModule]GAN.on_train_epoch_start                                                                                                                     \t|  1.9656e-06     \t|  10             \t|  1.9656e-05     \t|  1.8311e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  1.9197e-06     \t|  10             \t|  1.9197e-05     \t|  1.7884e-05     \t|\n",
      "|  [LightningModule]GAN.on_train_epoch_end                                                                                                                       \t|  1.8279e-06     \t|  10             \t|  1.8279e-05     \t|  1.7029e-05     \t|\n",
      "|  [LightningModule]GAN.on_save_checkpoint                                                                                                                       \t|  1.3713e-06     \t|  10             \t|  1.3713e-05     \t|  1.2775e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  8.166e-06      \t|  1              \t|  8.166e-06      \t|  7.6074e-06     \t|\n",
      "|  [LightningModule]GAN.configure_callbacks                                                                                                                      \t|  7.524e-06      \t|  1              \t|  7.524e-06      \t|  7.0093e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  5.886e-06      \t|  1              \t|  5.886e-06      \t|  5.4834e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  5.743e-06      \t|  1              \t|  5.743e-06      \t|  5.3502e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  4.52e-06       \t|  1              \t|  4.52e-06       \t|  4.2108e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  3.906e-06      \t|  1              \t|  3.906e-06      \t|  3.6388e-06     \t|\n",
      "|  [LightningModule]GAN.prepare_data                                                                                                                             \t|  3.549e-06      \t|  1              \t|  3.549e-06      \t|  3.3062e-06     \t|\n",
      "|  [LightningModule]GAN.setup                                                                                                                                    \t|  3.196e-06      \t|  1              \t|  3.196e-06      \t|  2.9774e-06     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  3.182e-06      \t|  1              \t|  3.182e-06      \t|  2.9643e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  3.101e-06      \t|  1              \t|  3.101e-06      \t|  2.8889e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  2.966e-06      \t|  1              \t|  2.966e-06      \t|  2.7631e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  2.852e-06      \t|  1              \t|  2.852e-06      \t|  2.6569e-06     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  2.177e-06      \t|  1              \t|  2.177e-06      \t|  2.0281e-06     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  2.156e-06      \t|  1              \t|  2.156e-06      \t|  2.0085e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  2.119e-06      \t|  1              \t|  2.119e-06      \t|  1.9741e-06     \t|\n",
      "|  [LightningModule]GAN.on_fit_end                                                                                                                               \t|  2.033e-06      \t|  1              \t|  2.033e-06      \t|  1.8939e-06     \t|\n",
      "|  [LightningModule]GAN.on_train_start                                                                                                                           \t|  2.008e-06      \t|  1              \t|  2.008e-06      \t|  1.8706e-06     \t|\n",
      "|  [LightningModule]GAN.teardown                                                                                                                                 \t|  1.981e-06      \t|  1              \t|  1.981e-06      \t|  1.8455e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  1.873e-06      \t|  1              \t|  1.873e-06      \t|  1.7449e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  1.842e-06      \t|  1              \t|  1.842e-06      \t|  1.716e-06      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  1.77e-06       \t|  1              \t|  1.77e-06       \t|  1.6489e-06     \t|\n",
      "|  [LightningModule]GAN.on_train_end                                                                                                                             \t|  1.678e-06      \t|  1              \t|  1.678e-06      \t|  1.5632e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  1.505e-06      \t|  1              \t|  1.505e-06      \t|  1.4021e-06     \t|\n",
      "|  [LightningModule]GAN.on_fit_start                                                                                                                             \t|  1.409e-06      \t|  1              \t|  1.409e-06      \t|  1.3126e-06     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dd680b8c044bf8aa563c476ec81cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.861 MB of 5.861 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Accuracy</td><td>▁▅▅▅▇▇████</td></tr><tr><td>Discriminator Loss</td><td>▄▂█▄▅▃▁▁▁▁</td></tr><tr><td>Discriminator Loss Fake</td><td>▃▁█▄▅▃▁▁▁▁</td></tr><tr><td>Discriminator Loss Real</td><td>█▄▄▅▃▂▁▁▁▁</td></tr><tr><td>FID Score</td><td>▁▁▂▃▅▅▇███</td></tr><tr><td>Generator Loss</td><td>▆▇▁▅▄▆████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Accuracy</td><td>1.0</td></tr><tr><td>Discriminator Loss</td><td>1.00701</td></tr><tr><td>Discriminator Loss Fake</td><td>0.69319</td></tr><tr><td>Discriminator Loss Real</td><td>0.31382</td></tr><tr><td>FID Score</td><td>717.49011</td></tr><tr><td>Generator Loss</td><td>0.6931</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-plant-62</strong> at: <a href='https://wandb.ai/karanravindra/gan/runs/esgpxpmb' target=\"_blank\">https://wandb.ai/karanravindra/gan/runs/esgpxpmb</a><br/>Synced 6 W&B file(s), 10 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240228_183756-esgpxpmb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"gan\", tags=[\"conv\", \"dcgan\"])\n",
    "trainer = Trainer(max_epochs=10, logger=logger, limit_val_batches=1, profiler=\"simple\", limit_train_batches=10)\n",
    "trainer.fit(gan, dataloader)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901d0ae279ad45379411bd6f720d0b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-star-47</strong> at: <a href='https://wandb.ai/karanravindra/gan/runs/kd46r2kw' target=\"_blank\">https://wandb.ai/karanravindra/gan/runs/kd46r2kw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240228_173457-kd46r2kw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
